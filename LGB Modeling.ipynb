{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "from typing import Union\n",
    "from tqdm.auto import tqdm as tqdm\n",
    "from sklearn import preprocessing\n",
    "import gc\n",
    "import lightgbm as lgb\n",
    "import random\n",
    "import os\n",
    "import re \n",
    "import lightgbm as lgb\n",
    "import dask.dataframe as dd\n",
    "from sklearn import preprocessing, metrics\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, RepeatedKFold, GroupKFold, GridSearchCV, train_test_split, TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22079892, 63)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_pickle('all_data_first.pkl')\n",
    "sample_submission = pd.read_csv('sample_submission.csv')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of the size of our data, we will be using LGB to do our modeling and feature selection.\n",
    "\n",
    "To ensure we don't violate the assumption of multicollinearity, before we run our models, let's take a glimpse of correlation between features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ATR                 False\n",
       "RS                   True\n",
       "ann_vol             False\n",
       "beta                 True\n",
       "bollinger           False\n",
       "cat_id              False\n",
       "dayofweek            True\n",
       "demand              False\n",
       "dept_id             False\n",
       "entropy              True\n",
       "event                True\n",
       "info_ratio           True\n",
       "is_weekend           True\n",
       "item_id             False\n",
       "month               False\n",
       "quarter             False\n",
       "relative_vol         True\n",
       "rolling_kurt_t30    False\n",
       "rolling_max_14      False\n",
       "rolling_max_180     False\n",
       "rolling_max_30      False\n",
       "rolling_max_60      False\n",
       "rolling_max_90      False\n",
       "rolling_mean_14     False\n",
       "rolling_mean_180    False\n",
       "rolling_mean_30     False\n",
       "rolling_mean_60     False\n",
       "rolling_mean_90     False\n",
       "rolling_min_14      False\n",
       "rolling_min_180      True\n",
       "rolling_min_30      False\n",
       "rolling_min_60      False\n",
       "rolling_min_90      False\n",
       "rolling_skew_t30    False\n",
       "rolling_std_14      False\n",
       "rolling_std_180     False\n",
       "rolling_std_30      False\n",
       "rolling_std_60      False\n",
       "rolling_std_90      False\n",
       "rrg_bench            True\n",
       "rrg_item             True\n",
       "sales_lag_15         True\n",
       "sales_lag_17         True\n",
       "sales_lag_19         True\n",
       "sales_lag_21         True\n",
       "sales_lag_23         True\n",
       "sales_lag_25         True\n",
       "sales_lag_27         True\n",
       "sales_lag_29         True\n",
       "sales_lag_31         True\n",
       "sales_lag_33         True\n",
       "sales_lag_35         True\n",
       "sell_price           True\n",
       "snap_CA              True\n",
       "snap_TX              True\n",
       "snap_WI              True\n",
       "store_id             True\n",
       "triple_exp          False\n",
       "week                False\n",
       "wm_yr_wk            False\n",
       "year                False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Those that return 'False' are those that are correlated with another feature by at least 83%.\n",
    "\n",
    "corr = data.corr()\n",
    "m = ~(corr.mask(np.eye(len(corr), dtype=bool)).abs() > 0.83).any()\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ca_model = data.loc[data['state_id']==0]\n",
    "# tx_model = data.loc[data['state_id']==1]\n",
    "# wi_model = data.loc[data['state_id']==2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running lgb on the entire dataset is too memory-intensive. So, we will first model the data by state to find feature importance. Contingent on the amount of features we drop, we hope that we can model the full data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F9</th>\n",
       "      <th>F10</th>\n",
       "      <th>F11</th>\n",
       "      <th>F12</th>\n",
       "      <th>F13</th>\n",
       "      <th>F14</th>\n",
       "      <th>F15</th>\n",
       "      <th>F16</th>\n",
       "      <th>F17</th>\n",
       "      <th>F18</th>\n",
       "      <th>F19</th>\n",
       "      <th>F20</th>\n",
       "      <th>F21</th>\n",
       "      <th>F22</th>\n",
       "      <th>F23</th>\n",
       "      <th>F24</th>\n",
       "      <th>F25</th>\n",
       "      <th>F26</th>\n",
       "      <th>F27</th>\n",
       "      <th>F28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12196</th>\n",
       "      <td>HOBBIES_1_001_TX_1_validation</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12197</th>\n",
       "      <td>HOBBIES_1_002_TX_1_validation</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12198</th>\n",
       "      <td>HOBBIES_1_003_TX_1_validation</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12199</th>\n",
       "      <td>HOBBIES_1_004_TX_1_validation</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12200</th>\n",
       "      <td>HOBBIES_1_005_TX_1_validation</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  id  F1  F2  F3  F4  F5  F6  F7  F8  F9  F10  \\\n",
       "12196  HOBBIES_1_001_TX_1_validation   0   0   0   0   0   0   0   0   0    0   \n",
       "12197  HOBBIES_1_002_TX_1_validation   0   0   0   0   0   0   0   0   0    0   \n",
       "12198  HOBBIES_1_003_TX_1_validation   0   0   0   0   0   0   0   0   0    0   \n",
       "12199  HOBBIES_1_004_TX_1_validation   0   0   0   0   0   0   0   0   0    0   \n",
       "12200  HOBBIES_1_005_TX_1_validation   0   0   0   0   0   0   0   0   0    0   \n",
       "\n",
       "       F11  F12  F13  F14  F15  F16  F17  F18  F19  F20  F21  F22  F23  F24  \\\n",
       "12196    0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "12197    0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "12198    0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "12199    0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "12200    0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "\n",
       "       F25  F26  F27  F28  \n",
       "12196    0    0    0    0  \n",
       "12197    0    0    0    0  \n",
       "12198    0    0    0    0  \n",
       "12199    0    0    0    0  \n",
       "12200    0    0    0    0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wi_items = '[A-Z]+_\\d{1}\\d?_\\d+_Wi\\w+'\n",
    "# sample_submission = sample_submission.loc[sample_submission['id'].str.contains(wi_items)]\n",
    "# sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['is_quarter_start' 'is_quarter_end' 'is_year_start' 'gap_placement'\\n 'gap_size' 'gap_start' 'number_of_gaps' 'is_month_start' 'is_year_end'\\n 'is_month_end'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-2bf9526b0de3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m            'number_of_gaps', 'is_month_start', 'is_year_end', 'is_month_end']\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_drop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3938\u001b[0m                                            \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3939\u001b[0m                                            \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3940\u001b[1;33m                                            errors=errors)\n\u001b[0m\u001b[0;32m   3941\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3942\u001b[0m     @rewrite_axis_style_signature('mapper', [('copy', True),\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3778\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3779\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3780\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3782\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   3810\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3811\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3812\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3813\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3814\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   4963\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'ignore'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4964\u001b[0m                 raise KeyError(\n\u001b[1;32m-> 4965\u001b[1;33m                     '{} not found in axis'.format(labels[mask]))\n\u001b[0m\u001b[0;32m   4966\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4967\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['is_quarter_start' 'is_quarter_end' 'is_year_start' 'gap_placement'\\n 'gap_size' 'gap_start' 'number_of_gaps' 'is_month_start' 'is_year_end'\\n 'is_month_end'] not found in axis\""
     ]
    }
   ],
   "source": [
    "'''Columns we can drop due to no importance'''\n",
    "\n",
    "to_drop = ['is_quarter_start','is_quarter_end', 'is_year_start',\n",
    "           'gap_placement', 'gap_size', 'gap_start',\n",
    "           'number_of_gaps', 'is_month_start', 'is_year_end', 'is_month_end']\n",
    "\n",
    "data.drop(to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [col for col in data.columns if col not in \n",
    "            ['id', 'demand', 'date', 'wm_yr_wk']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following lgb code was provided by: https://www.kaggle.com/ragnar123/asymmetric-loss-functions-lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_lgb(data, features, custom_asymmetric_train, custom_asymmetric_valid):\n",
    "    \n",
    "    # going to evaluate with the last 28 days\n",
    "    x_train = data[data['date'] <= '2016-03-27']\n",
    "    y_train = x_train['demand']\n",
    "    x_val = data[(data['date'] > '2016-03-27') & (data['date'] <= '2016-04-24')]\n",
    "    y_val = x_val['demand']\n",
    "    test = data[(data['date'] > '2016-04-24')]\n",
    "    del data\n",
    "    gc.collect()\n",
    "\n",
    "    # define random hyperparammeters\n",
    "    params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'regression',\n",
    "        'n_jobs': -1,\n",
    "        'seed': 42,\n",
    "        'learning_rate': 0.1,\n",
    "        'bagging_fraction': 0.75,\n",
    "        'bagging_freq': 10, \n",
    "        'colsample_bytree': 0.75}\n",
    "\n",
    "    train_set = lgb.Dataset(x_train[features], y_train)\n",
    "    val_set = lgb.Dataset(x_val[features], y_val)\n",
    "    \n",
    "    del x_train, y_train\n",
    "\n",
    "    model = lgb.train(params, train_set, num_boost_round = 2500, early_stopping_rounds = 50, \n",
    "                      valid_sets = [train_set, val_set], verbose_eval = 100, fobj = custom_asymmetric_train, \n",
    "                      feval = custom_asymmetric_valid)\n",
    "    \n",
    "    val_pred = model.predict(x_val[features])\n",
    "    y_pred = model.predict(test[features])\n",
    "    x_val['demand'] = val_pred\n",
    "    test['demand'] = y_pred\n",
    "    x_val = x_val[['id', 'date', 'demand']]\n",
    "    test = test[['id', 'date', 'demand']]\n",
    "\n",
    "    return x_val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(x_val, train_fold_df, valid_fold_df, calendar, sell_prices):\n",
    "    x_val = pd.pivot(x_val, index = 'id', columns = 'date', values = 'demand').reset_index()\n",
    "    x_val.columns = ['id'] + ['d_' + str(i) for i in range(1886, 1914)]\n",
    "    x_val = train_fold_df[['id']].merge(x_val, on = 'id')\n",
    "    x_val.drop('id', axis = 1, inplace = True)\n",
    "    evaluator = WRMSSEEvaluator(train_fold_df, valid_fold_df, calendar, sell_prices)\n",
    "    score = evaluator.score(x_val)\n",
    "    return score\n",
    "\n",
    "def predict(test, submission):\n",
    "    predictions = test[['id', 'date', 'demand']]\n",
    "    predictions = pd.pivot(predictions, index = 'id', columns = 'date', values = 'demand').reset_index()\n",
    "    predictions.columns = ['id'] + ['F' + str(i + 1) for i in range(28)]\n",
    "\n",
    "    evaluation_rows = [row for row in submission['id'] if 'evaluation' in row] \n",
    "    evaluation = submission[submission['id'].isin(evaluation_rows)]\n",
    "\n",
    "    validation = submission[['id']].merge(predictions, on = 'id')\n",
    "    final = pd.concat([validation, evaluation])\n",
    "    final.to_csv('submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define cost and eval functions\n",
    "def custom_asymmetric_train(y_pred, y_true):\n",
    "    y_true = y_true.get_label()\n",
    "    residual = (y_true - y_pred).astype(\"float\")\n",
    "    grad = np.where(residual < 0, -2 * residual, -2 * residual * 1.15)\n",
    "    hess = np.where(residual < 0, 2, 2 * 1.15)\n",
    "    return grad, hess\n",
    "\n",
    "def custom_asymmetric_valid(y_pred, y_true):\n",
    "    y_true = y_true.get_label()\n",
    "    residual = (y_true - y_pred).astype(\"float\")\n",
    "    loss = np.where(residual < 0, (residual ** 2) , (residual ** 2) * 1.15) \n",
    "    return \"custom_asymmetric_eval\", np.mean(loss), False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed everything\n",
    "seed_everything(42)\n",
    "# reading data\n",
    "data, calendar, sell_prices, submission, train_fold_df, valid_fold_df = read_data()\n",
    "# get feature columns, also ignoring some features because we dont have enough ram and they overffit\n",
    "features = [col for col in data.columns if col not in ['id', 'demand', 'part', 'date', 'wm_yr_wk', 'mean_demand_month', 'std_demand_month', 'max_demand_month', 'mean_demand_week', 'std_demand_week', \n",
    "                                                       'max_demand_week']]\n",
    "\n",
    "print(f'We are training with {len(features)} fetures')\n",
    "data.tail()\n",
    "\n",
    "# run model with asymmetric loss function\n",
    "x_val, test = run_lgb(data, features, custom_asymmetric_train, custom_asymmetric_valid)\n",
    "score = evaluate(x_val, train_fold_df, valid_fold_df, calendar, sell_prices)\n",
    "print(f'Our wrmsse is {score}')\n",
    "# predict test\n",
    "predict(test, submission)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our predictions, it is time to add back our slope and intercepts since we stripped them for feature engineering and modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Grabbing the regression attributes from the original sales df\n",
    "so we can add the slope back and scale back our submission values.'''\n",
    "\n",
    "from scipy.stats import linregress\n",
    "\n",
    "columns =['id','slope','intercept','std']\n",
    "index = range(0, len(sales))\n",
    "regress = pd.DataFrame(columns = columns, index = index)\n",
    "regress.fillna(0, inplace=True)\n",
    "d_cols = sales.columns[-712:]#since our data is only from d_1202 and beyond, we will only grab columns beyond those days.\n",
    "\n",
    "for j, item in enumerate(sales.id.unique()):\n",
    "    d_vals = np.squeeze(sales.loc[sales['id']==item][d_cols].T)\n",
    "    item_len = range(0,len(d_vals))\n",
    "    regress['id'].iloc[j] = item\n",
    "    regress['slope'].iloc[j] = linregress(d_vals, item_len)[0]\n",
    "    regress['intercept'].iloc[j] = linregress(d_vals, item_len)[1]\n",
    "    regress['std'].iloc[j] = linregress(d_vals, item_len)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>slope</th>\n",
       "      <th>intercept</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>24.833733</td>\n",
       "      <td>339.211582</td>\n",
       "      <td>8.431746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_002_CA_1_validation</td>\n",
       "      <td>-11.273509</td>\n",
       "      <td>359.315893</td>\n",
       "      <td>11.544826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_003_CA_1_validation</td>\n",
       "      <td>79.571820</td>\n",
       "      <td>327.225182</td>\n",
       "      <td>10.603538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_004_CA_1_validation</td>\n",
       "      <td>-8.532467</td>\n",
       "      <td>374.170764</td>\n",
       "      <td>3.337409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_005_CA_1_validation</td>\n",
       "      <td>11.664122</td>\n",
       "      <td>342.705507</td>\n",
       "      <td>6.167046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id      slope   intercept        std\n",
       "0  HOBBIES_1_001_CA_1_validation  24.833733  339.211582   8.431746\n",
       "1  HOBBIES_1_002_CA_1_validation -11.273509  359.315893  11.544826\n",
       "2  HOBBIES_1_003_CA_1_validation  79.571820  327.225182  10.603538\n",
       "3  HOBBIES_1_004_CA_1_validation  -8.532467  374.170764   3.337409\n",
       "4  HOBBIES_1_005_CA_1_validation  11.664122  342.705507   6.167046"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regress.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to repeat the same process for our predictions so we can scale properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data['bollinger'].isna(), 'bollinger'] = data['demand']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Grabbing the regression attributes from our predictions\n",
    "so we can add the slope back and scale back our submission values.'''\n",
    "\n",
    "columns =['id','slope','intercept','std']\n",
    "index = range(0, len(loop_df))\n",
    "final_reg = pd.DataFrame(columns = columns, index = index)\n",
    "final_reg.fillna(0, inplace=True)\n",
    "\n",
    "for j, item in enumerate(data['id'].unique()):\n",
    "    d_vals = np.squeeze(data.loc[data['id']==item]['bollinger'])\n",
    "    item_len = range(0,len(d_vals))\n",
    "    final_reg['id'].iloc[j] = item\n",
    "    final_reg['slope'].iloc[j] = linregress(d_vals, item_len)[0]\n",
    "    final_reg['intercept'].iloc[j] = linregress(d_vals, item_len)[1]\n",
    "    final_reg['std'].iloc[j] = linregress(d_vals, item_len)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>slope</th>\n",
       "      <th>intercept</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOUSEHOLD_1_030_CA_4_validation</td>\n",
       "      <td>-33.492083</td>\n",
       "      <td>375.962157</td>\n",
       "      <td>9.239507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOUSEHOLD_1_032_CA_4_validation</td>\n",
       "      <td>25.275446</td>\n",
       "      <td>319.539289</td>\n",
       "      <td>4.397030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOUSEHOLD_1_033_CA_4_validation</td>\n",
       "      <td>147.501947</td>\n",
       "      <td>308.887727</td>\n",
       "      <td>10.088969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOUSEHOLD_1_034_CA_4_validation</td>\n",
       "      <td>1.020886</td>\n",
       "      <td>355.091359</td>\n",
       "      <td>10.804175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOUSEHOLD_1_035_CA_4_validation</td>\n",
       "      <td>207.832800</td>\n",
       "      <td>344.991600</td>\n",
       "      <td>26.329572</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                id       slope   intercept        std\n",
       "0  HOUSEHOLD_1_030_CA_4_validation  -33.492083  375.962157   9.239507\n",
       "1  HOUSEHOLD_1_032_CA_4_validation   25.275446  319.539289   4.397030\n",
       "2  HOUSEHOLD_1_033_CA_4_validation  147.501947  308.887727  10.088969\n",
       "3  HOUSEHOLD_1_034_CA_4_validation    1.020886  355.091359  10.804175\n",
       "4  HOUSEHOLD_1_035_CA_4_validation  207.832800  344.991600  26.329572"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regress = regress.set_index('id')\n",
    "regress = regress.reindex(index=final_reg['id'])\n",
    "regress = regress.reset_index()\n",
    "regress.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
