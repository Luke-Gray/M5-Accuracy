{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data manipulation packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import re\n",
    "\n",
    "#visualization tools\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30490, 1919)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales = pd.read_csv('sales_train_validation.csv')\n",
    "cal = pd.read_csv('calendar.csv', parse_dates = ['date'])\n",
    "sales.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will address the large gaps within each item's time series by using Gausian Process Regression. After handling this, we will then address the intermittent demand we see in many of the series. I will explain that process after first handling the missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we are indexing on where we observe the large 0 gaps. if the occur in the beginning, we will reverse our data to train the missing data. If the gaps occur in the middle and end, then we will model the data in its regular order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''As observed above, some of the items, for one reason or another, have limited history throughout the time series.\n",
    "The following script will find the items that have limited history, the amount of consecutive zeros within the time\n",
    "series, and where exactly they occur in the series (i.e. 'beginning', 'middle', 'end').\n",
    "'''\n",
    "\n",
    "import itertools\n",
    "\n",
    "limited_items = {}\n",
    "d_cols = [col for col in sales.columns if 'd_' in col]\n",
    "\n",
    "for item_id in sales['id']:\n",
    "    df = sales.loc[sales['id'] == item_id][d_cols].T\n",
    "    df = df.rename(columns={sales.index[sales['id']==item_id].to_list()[0]:item_id}) # Name it correctly\n",
    "    df = df.reset_index().rename(columns={'index': 'd'}) # make the index \"d\"\n",
    "    df = df.merge(cal, how='left', validate='1:1')\n",
    "    \n",
    "    rolled = np.asarray(df.iloc[:,1].astype(int))\n",
    "    \n",
    "    zero_consec, zero_count = [0], 0\n",
    "    full_series = []\n",
    "    \n",
    "    condition = np.where(rolled==0,'true','false')\n",
    "    zero_groups = [ sum( 1 for _ in group ) for key, group in itertools.groupby( condition ) if key ]\n",
    "    zero_gap = (zero_groups.index(max(zero_groups))/len(zero_groups))*100\n",
    "\n",
    "    if zero_gap<35:\n",
    "        zero_location = 'beginning'\n",
    "    elif zero_gap <= 35 or zero_gap<=75:\n",
    "        zero_location = 'middle'\n",
    "    else:\n",
    "        zero_location = 'end'\n",
    "\n",
    "    for val in range(len(rolled)):\n",
    "        condition = val == 0\n",
    "        if rolled[val]==0:\n",
    "            zero_count+=1\n",
    "        else:\n",
    "            if zero_count>zero_consec[0]:\n",
    "                zero_consec[0] = zero_count\n",
    "                zero_ind = val-zero_count\n",
    "            else:\n",
    "                zero_count = 0\n",
    "    if zero_consec[0]>100:\n",
    "        limited_items[item_id] = zero_consec[0], zero_location, zero_ind\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('HOBBIES_1_001_CA_1_validation', (916, 'beginning', 2)),\n",
       " ('HOBBIES_1_002_CA_1_validation', (150, 'beginning', 2)),\n",
       " ('HOBBIES_1_003_CA_1_validation', (1109, 'beginning', 3)),\n",
       " ('HOBBIES_1_005_CA_1_validation', (112, 'beginning', 0)),\n",
       " ('HOBBIES_1_006_CA_1_validation', (429, 'beginning', 0)),\n",
       " ('HOBBIES_1_007_CA_1_validation', (530, 'beginning', 0)),\n",
       " ('HOBBIES_1_008_CA_1_validation', (185, 'middle', 543)),\n",
       " ('HOBBIES_1_009_CA_1_validation', (143, 'end', 1644)),\n",
       " ('HOBBIES_1_010_CA_1_validation', (110, 'beginning', 4)),\n",
       " ('HOBBIES_1_011_CA_1_validation', (557, 'beginning', 7))]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##first 10 items in limited_items\n",
    "\n",
    "from itertools import islice\n",
    "\n",
    "def take(n, iterable):\n",
    "    \"Return first n items of the iterable as a list\"\n",
    "    return list(islice(iterable, n))\n",
    "\n",
    "first_ten = take(10, limited_items.items())\n",
    "first_ten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we've grabbed all of the items that have more than 100 consecutive days without selling an item. Additionally, we've grabbed how large the zero gap is, where in the time series it occured, and at what index the gap begins. This way, we can make a train and test set for a GPR model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think the best way to optimize parameters for the model is to aggregate the mean values for each category in a rolling window and do a Bayesian Opt. Hopefully the avg will represent the overall noise of the items within the category and, from there, we will model each item to fill these zero gaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
